{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Guardrail Classifier (sürətli və praktik)\n",
        "\n",
        "Məqsəd:\n",
        "1) Balanslı training set yaratmaq (`UNSAFE=1`, `SAFE=0`)\n",
        "2) 1 epoch ilə sürətli training\n",
        "3) Modelin işlədiyini sanity check ilə göstərmək\n",
        "\n",
        "Qeyd: Laptop/CPU mühitinə görə parametrləri sürət üçün seçmişəm (yüksək batch, kiçik max_len və az data). Lokala klonlandıqdan sonra laptop göstəricilərindən asılı olaraq parametrlərdə dəyişiklik edə bilərsiniz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repo root: d:\\github_repos\\kontakt_home_task\\task3\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import os, sys, subprocess\n",
        "\n",
        "ROOT = Path.cwd()\n",
        "if ROOT.name.lower() == \"notebooks\":\n",
        "    ROOT = ROOT.parent\n",
        "\n",
        "os.chdir(ROOT)\n",
        "print(\"Repo root:\", Path.cwd())\n",
        "\n",
        "PYTHONPATH = str(Path.cwd() / \"src\")\n",
        "ENV = os.environ.copy()\n",
        "ENV[\"PYTHONPATH\"] = PYTHONPATH + (os.pathsep + ENV[\"PYTHONPATH\"] if ENV.get(\"PYTHONPATH\") else \"\")\n",
        "\n",
        "def run(cmd):\n",
        "    \"\"\"Always run with the same python as this notebook kernel + correct PYTHONPATH.\"\"\"\n",
        "    if isinstance(cmd, str):\n",
        "        cmd = cmd.split()\n",
        "    print(\"RUN:\", \" \".join(cmd))\n",
        "    return subprocess.run(cmd, env=ENV, check=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a15b3167",
      "metadata": {},
      "source": [
        "## Bu bootstrap nəyə lazımdır?\n",
        "\n",
        "Notebook-lar `task3/notebooks/` içində olduğu üçün, birbaşa işlətsək `scripts/...` və `src/...` yolları tapılmaya bilər.\n",
        "\n",
        "Bu blok nə edir?\n",
        "\n",
        "- **Repo root-a keçir (`task3/`)** — yollar düz işləsin deyə  \n",
        "- **`PYTHONPATH=src` verir** — `import pii_guard...` xətası çıxmasın deyə  \n",
        "- **`sys.executable` istifadə edir** — notebook-un istifadə etdiyi Python ilə eyni interpreter işləsin deyə  \n",
        "\n",
        "Yəni “məndə işləyir, səndə işləmir” tipli problemləri azaldır :D\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset building (8k unsafe + 8k safe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RUN: d:\\github_repos\\kontakt_home_task\\.venv\\Scripts\\python.exe scripts/build_train_classifier_json.py --filter_safe_pii --max_unsafe 4000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "CompletedProcess(args=['d:\\\\github_repos\\\\kontakt_home_task\\\\.venv\\\\Scripts\\\\python.exe', 'scripts/build_train_classifier_json.py', '--filter_safe_pii', '--max_unsafe', '4000'], returncode=0)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run([sys.executable, \"scripts/build_train_classifier_json.py\", \"--filter_safe_pii\", \"--max_unsafe\", \"4000\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "362dd26b",
      "metadata": {},
      "source": [
        "Script-in nəticəsi: [data/processed/train_classifier.json](../data/processed/train_classifier.json)\n",
        "\n",
        "Bu faylda hər sətir belədir:\n",
        "- `text`  → cümlə\n",
        "- `label` → 0 (SAFE) / 1 (UNSAFE)\n",
        "- `split` → train / validation\n",
        "\n",
        "Yəni növbəti mərhələdə modelə “hazır dataset” veririk."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train classifier (1 epoch, batch 256, max_len)\n",
        "256 seçmə səbəbimiz modelin işləkliyini vaxt itirmədən icmali şəkildə göstərməkdir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e390b392",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RUN: d:\\github_repos\\kontakt_home_task\\.venv\\Scripts\\python.exe -m pii_guard.training.train_classifier --epochs 1 --batch 256 --max_len 24\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "CompletedProcess(args=['d:\\\\github_repos\\\\kontakt_home_task\\\\.venv\\\\Scripts\\\\python.exe', '-m', 'pii_guard.training.train_classifier', '--epochs', '1', '--batch', '256', '--max_len', '24'], returncode=0)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run([sys.executable, \"-m\", \"pii_guard.training.train_classifier\",\n",
        "     \"--epochs\", \"1\", \"--batch\", \"256\", \"--max_len\", \"24\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quick sanity inference (PyTorch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "669094c9",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The tokenizer you are loading from 'models/classifier/pytorch' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DistilBertForSequenceClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): DistilBertSdpaAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_dir = \"models/classifier/pytorch\"\n",
        "tok = AutoTokenizer.from_pretrained(model_dir, use_fast=True)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "45e580a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "samples = [\n",
        "    \"Salam, sabah görüşərik.\",\n",
        "    \"Mənim telefon nömrəm +994 50 123 45 67-dir.\",\n",
        "    \"Kartım 4169 1234 5678 9012, adım Aysel Mammadova.\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "bf1d7b73",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNSAFE prob=0.661 | Salam, sabah görüşərik.\n",
            "UNSAFE prob=0.895 | Mənim telefon nömrəm +994 50 123 45 67-dir.\n",
            "UNSAFE prob=0.876 | Kartım 4169 1234 5678 9012, adım Aysel Mammadova.\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    for s in samples:\n",
        "        enc = tok(s, return_tensors=\"pt\", truncation=True, max_length=96)\n",
        "        logits = model(**enc).logits[0].cpu().numpy()\n",
        "        exps = np.exp(logits - logits.max())\n",
        "        probs = exps / exps.sum()\n",
        "        print(f\"UNSAFE prob={float(probs[1]):.3f} | {s}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
